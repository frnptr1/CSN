#################
source("commonFunctions.R")
source("01.BA_original.R")
source("02.BA_growth_rand_att.R")
source("03.BA_no_growth.R")
test = as.data.frame(cbind(table.BA[,-1],
table.BA.no.growth[,-1],
table.BA.Rand[,-1]))
b = test[,1]
nlsLM(b ~ a*t, start=list(a=1))
# sequence of values
t = seq(t.max+1)
nlsLM(b ~ a*t, start=list(a=1))
nlsLM(b~a*sqrt(t),start=list(a=1))
nlsLM(b~a*(t)^b, start = list(a=0.1, b=1))
nlsLM(b~a*exp(c*t), start = list(a=1,c=0.0001))
nlsLM(b~a*(log(abs(t+d1))), start=list(a=0.1 ,d1=1))
nlsLM(b ~ a*t+d,start=list(a=1, d=1))
nlsLM(i~a*sqrt(t)+d,start=list(a=1, d=1))
nlsLM(b~a*sqrt(t)+d,start=list(a=1, d=1))
nlsLM(b~a*((t)^b)+d, start = list(a=0.1, b=1, d=1))
nlsLM(b~a*((t)^b)+d, start = list(a=0.1, b=1, d=1), nls.lm.control(maxiter = 500))
nlsLM(b~a*((t)^b)+d, start = list(a=0.1, b=1, d=1), control=nls.lm.control(maxiter = 500))
nlsLM(b~a*((t)^b)+d, start = list(a=0.1, b=1, d=1), control=nls.lm.control(maxiter = 100))
nlsLM(b~a*((t)^b)+d, start = list(a=0.1, b=1, d=1), control=nls.lm.control(maxiter = 150))
nlsLM(b~d+a*exp(c*t), start = list(a=1,c=0.01, d=0.1))
nlsLM(i~a*(log(abs(t+d1)))+d2, start=list(a=10 ,d1=1000, d2=-100))
nlsLM(b~a*(log(abs(t+d1)))+d2, start=list(a=10 ,d1=1000, d2=-100))
c = nlsLM(b~a*(log(abs(t+d1)))+d2, start=list(a=10 ,d1=1000, d2=-100))
c$call
summary(c)
c = summry(c)
c = summqry(c)
c = summary(c)
c$coefficients
c$coefficients[,1]
c = nlsLM(b~a*(log(abs(t+d1)))+d2, start=list(a=10 ,d1=1000, d2=-100))
predict(c)
prova = function(i){
# models without intercept
model0 = nlsLM(b ~ a*t, start=list(a=1))
model1 = nlsLM(b ~ a*sqrt(t),start=list(a=1))
model2 = nlsLM(b ~ a*(t)^b, start = list(a=0.1, b=1))
model3 = nlsLM(b ~ a*exp(c*t), start = list(a=1,c=0.0001))
model4 = nlsLM(b ~ a*(log(abs(t+d1))), start=list(a=0.1 ,d1=1))
# models with intercept
model0i = nlsLM(b ~ a*t+d,start=list(a=1, d=1))
model1i = nlsLM(b~a*sqrt(t)+d,start=list(a=1, d=1))
model2i = nlsLM(b~a*((t)^b)+d, start = list(a=0.1, b=1, d=1), control=nls.lm.control(maxiter = 150))
model3i = nlsLM(b~d+a*exp(c*t), start = list(a=1,c=0.01, d=0.1))
model4i = nlsLM(b~a*(log(abs(t+d1)))+d2, start=list(a=10 ,d1=1000, d2=-100))
# the models computer are now inserted in a list to compact the code
models_list = list(model0, model1, model2, model3, model4,
model0i, model1i, model2i, model3i, model4i)
# get the sum of residuals squared of the models,the aic value and the parmeters found
get_RSS = function(x) return(sum(i-predict(x))^2) #check
get_AIC = function(rss, par) return(t.max*log(2*pi) + t.max*log(rss/t.max) + t.max + 2*(par + 1))
get_params = function(x) return(as.vector(summary(x)$coefficents[,1]))
# parameters of each model
mod_params = c(1, 1, 2, 2, 2, 2, 2, 3, 3, 3)
# get parameter estimate from models..
pm = lapply(models_list, get_params)
# replace missing parameters with NA (some models have 1 params others 2, others 3)..
pm = lapply(pm, `length<-`, max(lengths(pm)))
# transform it into matrix to append in the dataframe
pm = do.call(rbind, pm)
# residual sum of squares
rss = sapply(models_list, get_RSS)
# Akaike information criterion
aic_vect = mapply(get_AIC,rss, mod_params)
# model selection growth + preferential attachment
ms_gp = data.frame("RSS"= rss,      # residual square of sum no intercept
"AIC"=aic_vect,  # aic no intercept
"Param1"=pm[,1],          # param 1
"Param2"=pm[,2],          # param 2
"Param3"=pm[,3])          # param
# add model names to df
rownames(ms_gp) = c("linear regr", "plaw 0.5", "plaw", "expo", "log",
"linear regr+i", "plaw 0.5+i", "plaw+i", "expo+i", "log+i")
# show the one that fit better
better_fit = ms_gp[which.min(ms_gp$AIC),]
}
apply(test, 2, prova)
prova = function(i){
# models without intercept
model0 = nlsLM(b ~ a*t, start=list(a=1))
model1 = nlsLM(b ~ a*sqrt(t),start=list(a=1))
model2 = nlsLM(b ~ a*(t)^b, start = list(a=0.1, b=1))
model3 = nlsLM(b ~ a*exp(c*t), start = list(a=1,c=0.0001))
model4 = nlsLM(b ~ a*(log(abs(t+d1))), start=list(a=0.1 ,d1=1))
# models with intercept
model0i = nlsLM(b ~ a*t+d,start=list(a=1, d=1))
model1i = nlsLM(b~a*sqrt(t)+d,start=list(a=1, d=1))
model2i = nlsLM(b~a*((t)^b)+d, start = list(a=0.1, b=1, d=1), control=nls.lm.control(maxiter = 150))
model3i = nlsLM(b~d+a*exp(c*t), start = list(a=1,c=0.01, d=0.1))
model4i = nlsLM(b~a*(log(abs(t+d1)))+d2, start=list(a=10 ,d1=1000, d2=-100))
# the models computer are now inserted in a list to compact the code
models_list = list(model0, model1, model2, model3, model4,
model0i, model1i, model2i, model3i, model4i)
# get the sum of residuals squared of the models,the aic value and the parmeters found
get_RSS = function(x) return(sum(i-predict(x))^2) #check
get_AIC = function(rss, par) return(t.max*log(2*pi) + t.max*log(rss/t.max) + t.max + 2*(par + 1))
get_params = function(x) return(as.vector(summary(x)$coefficents[,1]))
# parameters of each model
mod_params = c(1, 1, 2, 2, 2, 2, 2, 3, 3, 3)
# get parameter estimate from models..
pm = lapply(models_list, get_params)
# replace missing parameters with NA (some models have 1 params others 2, others 3)..
pm = lapply(pm, `length<-`, max(lengths(pm)))
# transform it into matrix to append in the dataframe
pm = do.call(rbind, pm)
# residual sum of squares
rss = sapply(models_list, get_RSS)
# Akaike information criterion
aic_vect = mapply(get_AIC,rss, mod_params)
# model selection growth + preferential attachment
ms_gp = data.frame("RSS"= rss,      # residual square of sum no intercept
"AIC"=aic_vect,  # aic no intercept
"Param1"=pm[,1],          # param 1
"Param2"=pm[,2],          # param 2
"Param3"=pm[,3])          # param
# add model names to df
rownames(ms_gp) = c("linear regr", "plaw 0.5", "plaw", "expo", "log",
"linear regr+i", "plaw 0.5+i", "plaw+i", "expo+i", "log+i")
# show the one that fit better
better_fit = ms_gp[which.min(ms_gp$AIC),]
print(better_fit)
}
apply(test, 2, prova)
# sequence of values
t = seq(t.max+1)
# get the sum of residuals squared of the models,the aic value and the parmeters found
get_RSS = function(x) return(sum(i-predict(x))^2) #check
get_AIC = function(rss, par) return(t.max*log(2*pi) + t.max*log(rss/t.max) + t.max + 2*(par + 1))
get_params = function(x) return(as.vector(summary(x)$coefficents[,1]))
# parameters of each model
mod_params = c(1, 1, 2, 2, 2, 2, 2, 3, 3, 3)
prova = function(i){
# models without intercept
model0 = nlsLM(i ~ a*t, start=list(a=1))
model1 = nlsLM(i ~ a*sqrt(t),start=list(a=1))
model2 = nlsLM(i ~ a*(t)^b, start = list(a=0.1, b=1))
model3 = nlsLM(i ~ a*exp(c*t), start = list(a=1,c=0.0001))
model4 = nlsLM(i ~ a*(log(abs(t+d1))), start=list(a=0.1 ,d1=1))
# models with intercept
model0i = nlsLM(i ~ a*t+d,start=list(a=1, d=1))
model1i = nlsLM(i ~ a*sqrt(t)+d,start=list(a=1, d=1))
model2i = nlsLM(i ~ a*((t)^b)+d, start = list(a=0.1, b=1, d=1), control=nls.lm.control(maxiter = 150))
model3i = nlsLM(i ~ d+a*exp(c*t), start = list(a=1,c=0.01, d=0.1))
model4i = nlsLM(i ~ a*(log(abs(t+d1)))+d2, start=list(a=10 ,d1=1000, d2=-100))
# the models computer are now inserted in a list to compact the code
models_list = list(model0, model1, model2, model3, model4,
model0i, model1i, model2i, model3i, model4i)
# get parameter estimate from models..
pm = lapply(models_list, get_params)
# replace missing parameters with NA (some models have 1 params others 2, others 3)..
pm = lapply(pm, `length<-`, max(lengths(pm)))
# transform it into matrix to append in the dataframe
pm = do.call(rbind, pm)
# residual sum of squares
rss = sapply(models_list, get_RSS)
# Akaike information criterion
aic_vect = mapply(get_AIC,rss, mod_params)
# model selection growth + preferential attachment
ms_gp = data.frame("RSS"= rss,      # residual square of sum no intercept
"AIC"=aic_vect,  # aic no intercept
"Param1"=pm[,1],          # param 1
"Param2"=pm[,2],          # param 2
"Param3"=pm[,3])          # param
# add model names to df
rownames(ms_gp) = c("linear regr", "plaw 0.5", "plaw", "expo", "log",
"linear regr+i", "plaw 0.5+i", "plaw+i", "expo+i", "log+i")
# show the one that fit better
better_fit = ms_gp[which.min(ms_gp$AIC),]
print(better_fit)
}
apply(test,2,prova)
prova = function(i){
# models without intercept
model0 = nlsLM(i ~ a*t, start=list(a=1))
model1 = nlsLM(i ~ a*sqrt(t),start=list(a=1))
model2 = nlsLM(i ~ a*(t)^b, start = list(a=0.1, b=1))
model3 = nlsLM(i ~ a*exp(c*t), start = list(a=1,c=0.0001))
model4 = nlsLM(i ~ a*(log(abs(t+d1))), start=list(a=0.1 ,d1=1))
# models with intercept
model0i = nlsLM(i ~ a*t+d,start=list(a=1, d=1))
model1i = nlsLM(i ~ a*sqrt(t)+d,start=list(a=1, d=1))
model2i = nlsLM(i ~ a*((t)^b)+d, start = list(a=0.1, b=1, d=1), control=nls.lm.control(maxiter = 150))
model3i = nlsLM(i ~ d+a*exp(c*t), start = list(a=1,c=0.01, d=0.1))
model4i = nlsLM(i ~ a*(log(abs(t+d1)))+d2, start=list(a=10 ,d1=1000, d2=-100))
# the models computer are now inserted in a list to compact the code
models_list = list(model0, model1, model2, model3, model4,
model0i, model1i, model2i, model3i, model4i)
get_RSS = function(x) return(sum(i-predict(x))^2) #check
get_AIC = function(rss, par) return(t.max*log(2*pi) + t.max*log(rss/t.max) + t.max + 2*(par + 1))
get_params = function(x) return(as.vector(summary(x)$coefficents[,1]))
# get parameter estimate from models..
pm = lapply(models_list, get_params)
# replace missing parameters with NA (some models have 1 params others 2, others 3)..
pm = lapply(pm, `length<-`, max(lengths(pm)))
# transform it into matrix to append in the dataframe
pm = do.call(rbind, pm)
# residual sum of squares
rss = sapply(models_list, get_RSS)
# Akaike information criterion
aic_vect = mapply(get_AIC,rss, mod_params)
# model selection growth + preferential attachment
ms_gp = data.frame("RSS"= rss,      # residual square of sum no intercept
"AIC"=aic_vect,  # aic no intercept
"Param1"=pm[,1],          # param 1
"Param2"=pm[,2],          # param 2
"Param3"=pm[,3])          # param
# add model names to df
rownames(ms_gp) = c("linear regr", "plaw 0.5", "plaw", "expo", "log",
"linear regr+i", "plaw 0.5+i", "plaw+i", "expo+i", "log+i")
# show the one that fit better
better_fit = ms_gp[which.min(ms_gp$AIC),]
print(better_fit)
}
apply(test,2,prova)
# parameters of each model
mod_params = c(1, 1, 2, 2, 2, 2, 2, 3, 3, 3)
prova = function(i){
# models without intercept
model0 = nlsLM(i ~ a*t, start=list(a=1))
model1 = nlsLM(i ~ a*sqrt(t),start=list(a=1))
model2 = nlsLM(i ~ a*(t)^b, start = list(a=0.1, b=1))
model3 = nlsLM(i ~ a*exp(c*t), start = list(a=1,c=0.0001))
model4 = nlsLM(i ~ a*(log(abs(t+d1))), start=list(a=0.1 ,d1=1))
# models with intercept
model0i = nlsLM(i ~ a*t+d,start=list(a=1, d=1))
model1i = nlsLM(i ~ a*sqrt(t)+d,start=list(a=1, d=1))
model2i = nlsLM(i ~ a*((t)^b)+d, start = list(a=0.1, b=1, d=1), control=nls.lm.control(maxiter = 150))
model3i = nlsLM(i ~ d+a*exp(c*t), start = list(a=1,c=0.01, d=0.1))
model4i = nlsLM(i ~ a*(log(abs(t+d1)))+d2, start=list(a=10 ,d1=1000, d2=-100))
# the models computer are now inserted in a list to compact the code
models_list = list(model0, model1, model2, model3, model4,
model0i, model1i, model2i, model3i, model4i)
get_RSS = function(x) return(sum(i-predict(x))^2) #check
get_AIC = function(rss, par) return(t.max*log(2*pi) + t.max*log(rss/t.max) + t.max + 2*(par + 1))
get_params = function(x) return(as.vector(summary(x)$coefficents[,1]))
# get parameter estimate from models..
pm = lapply(models_list, get_params)
# replace missing parameters with NA (some models have 1 params others 2, others 3)..
pm = lapply(pm, `length<-`, max(lengths(pm)))
# transform it into matrix to append in the dataframe
pm = do.call(rbind, pm)
# residual sum of squares
rss = sapply(models_list, get_RSS)
# Akaike information criterion
aic_vect = mapply(get_AIC,rss, mod_params)
# model selection growth + preferential attachment
ms_gp = data.frame("RSS"= rss,      # residual square of sum no intercept
"AIC"=aic_vect)  # aic no intercept
#"Param1"=pm[,1],          # param 1
#"Param2"=pm[,2],          # param 2
#"Param3"=pm[,3])          # param
# add model names to df
rownames(ms_gp) = c("linear regr", "plaw 0.5", "plaw", "expo", "log",
"linear regr+i", "plaw 0.5+i", "plaw+i", "expo+i", "log+i")
# show the one that fit better
better_fit = ms_gp[which.min(ms_gp$AIC),]
print(better_fit)
}
apply(test,2,prova)
model0 = nlsLM(b ~ a*t, start=list(a=1))
model1 = nlsLM(b~ a*sqrt(t),start=list(a=1))
model2 = nlsLM(b ~ a*(t)^b, start = list(a=0.1, b=1))
model3 = nlsLM(b ~ a*exp(c*t), start = list(a=1,c=0.0001))
model4 = nlsLM(b ~ a*(log(abs(t+d1))), start=list(a=0.1 ,d1=1))
# models with intercept
model0i = nlsLM(b ~ a*t+d,start=list(a=1, d=1))
model1i = nlsLM(b ~ a*sqrt(t)+d,start=list(a=1, d=1))
model2i = nlsLM(b ~ a*((t)^b)+d, start = list(a=0.1, b=1, d=1), control=nls.lm.control(maxiter = 150))
model3i = nlsLM(b ~ d+a*exp(c*t), start = list(a=1,c=0.01, d=0.1))
model4i = nlsLM(b ~ a*(log(abs(t+d1)))+d2, start=list(a=10 ,d1=1000, d2=-100))
models_list = list(model0, model1, model2, model3, model4,
model0i, model1i, model2i, model3i, model4i)
get_RSS = function(x) return(sum(b-predict(x))^2) #check
get_AIC = function(rss, par) return(t.max*log(2*pi) + t.max*log(rss/t.max) + t.max + 2*(par + 1))
get_params = function(x) return(as.vector(summary(x)$coefficents[,1]))
# get parameter estimate from models..
pm = lapply(models_list, get_params)
# replace missing parameters with NA (some models have 1 params others 2, others 3)..
pm = lapply(pm, `length<-`, max(lengths(pm)))
# transform it into matrix to append in the dataframe
pm = do.call(rbind, pm)
# get parameter estimate from models..
pm = lapply(models_list, get_params)
get_params(model0)
summary(model0)
summary(model0)$coefficents
r = summary(model0)
summary(model0)$coefficients
prova = function(i){
# models without intercept
model0 = nlsLM(i ~ a*t, start=list(a=1))
model1 = nlsLM(i ~ a*sqrt(t),start=list(a=1))
model2 = nlsLM(i ~ a*(t)^b, start = list(a=0.1, b=1))
model3 = nlsLM(i ~ a*exp(c*t), start = list(a=1,c=0.0001))
model4 = nlsLM(i ~ a*(log(abs(t+d1))), start=list(a=0.1 ,d1=1))
# models with intercept
model0i = nlsLM(i ~ a*t+d,start=list(a=1, d=1))
model1i = nlsLM(i ~ a*sqrt(t)+d,start=list(a=1, d=1))
model2i = nlsLM(i ~ a*((t)^b)+d, start = list(a=0.1, b=1, d=1), control=nls.lm.control(maxiter = 150))
model3i = nlsLM(i ~ d+a*exp(c*t), start = list(a=1,c=0.01, d=0.1))
model4i = nlsLM(i ~ a*(log(abs(t+d1)))+d2, start=list(a=10 ,d1=1000, d2=-100))
# the models computer are now inserted in a list to compact the code
models_list = list(model0, model1, model2, model3, model4,
model0i, model1i, model2i, model3i, model4i)
get_RSS = function(x) return(sum(i-predict(x))^2) #check
get_AIC = function(rss, par) return(t.max*log(2*pi) + t.max*log(rss/t.max) + t.max + 2*(par + 1))
get_params = function(x) return(as.vector(summary(x)$coefficents[,1]))
# get parameter estimate from models..
pm = lapply(models_list, get_params)
# replace missing parameters with NA (some models have 1 params others 2, others 3)..
pm = lapply(pm, `length<-`, max(lengths(pm)))
# transform it into matrix to append in the dataframe
pm = do.call(rbind, pm)
# residual sum of squares
rss = sapply(models_list, get_RSS)
# Akaike information criterion
aic_vect = mapply(get_AIC,rss, mod_params)
# model selection growth + preferential attachment
ms_gp = data.frame("RSS"= rss,      # residual square of sum no intercept
"AIC"=aic_vect)  # aic no intercept
#"Param1"=pm[,1],          # param 1
#"Param2"=pm[,2],          # param 2
#"Param3"=pm[,3])          # param
# add model names to df
rownames(ms_gp) = c("linear regr", "plaw 0.5", "plaw", "expo", "log",
"linear regr+i", "plaw 0.5+i", "plaw+i", "expo+i", "log+i")
# show the one that fit better
better_fit = ms_gp[which.min(ms_gp$AIC),]
print(better_fit)
}
apply(test,2,prova)
prova = function(i){
# models without intercept
model0 = nlsLM(i ~ a*t, start=list(a=1))
model1 = nlsLM(i ~ a*sqrt(t),start=list(a=1))
model2 = nlsLM(i ~ a*(t)^b, start = list(a=0.1, b=1))
model3 = nlsLM(i ~ a*exp(c*t), start = list(a=1,c=0.0001))
model4 = nlsLM(i ~ a*(log(abs(t+d1))), start=list(a=0.1 ,d1=1))
# models with intercept
model0i = nlsLM(i ~ a*t+d,start=list(a=1, d=1))
model1i = nlsLM(i ~ a*sqrt(t)+d,start=list(a=1, d=1))
model2i = nlsLM(i ~ a*((t)^b)+d, start = list(a=0.1, b=1, d=1), control=nls.lm.control(maxiter = 150))
model3i = nlsLM(i ~ d+a*exp(c*t), start = list(a=1,c=0.01, d=0.1))
model4i = nlsLM(i ~ a*(log(abs(t+d1)))+d2, start=list(a=10 ,d1=1000, d2=-100))
# the models computer are now inserted in a list to compact the code
models_list = list(model0, model1, model2, model3, model4,
model0i, model1i, model2i, model3i, model4i)
get_RSS = function(x) return(sum(i-predict(x))^2) #check
get_AIC = function(rss, par) return(t.max*log(2*pi) + t.max*log(rss/t.max) + t.max + 2*(par + 1))
get_params = function(x) return(as.vector(summary(x)$coefficents[,1]))
# get parameter estimate from models..
pm = lapply(models_list, get_params)
# replace missing parameters with NA (some models have 1 params others 2, others 3)..
pm = lapply(pm, `length<-`, max(lengths(pm)))
# transform it into matrix to append in the dataframe
pm = do.call(rbind, pm)
# residual sum of squares
rss = sapply(models_list, get_RSS)
# Akaike information criterion
aic_vect = mapply(get_AIC,rss, mod_params)
# model selection growth + preferential attachment
ms_gp = data.frame("RSS"= rss,      # residual square of sum no intercept
"AIC"=aic_vect,  # aic no intercept
"Param1"=pm[,1],          # param 1
"Param2"=pm[,2],          # param 2
"Param3"=pm[,3])          # param
# add model names to df
rownames(ms_gp) = c("linear regr", "plaw 0.5", "plaw", "expo", "log",
"linear regr+i", "plaw 0.5+i", "plaw+i", "expo+i", "log+i")
# show the one that fit better
better_fit = ms_gp[which.min(ms_gp$AIC),]
print(better_fit)
}
apply(test,2,prova)
prova = function(i){
# models without intercept
model0 = nlsLM(i ~ a*t, start=list(a=1))
model1 = nlsLM(i ~ a*sqrt(t),start=list(a=1))
model2 = nlsLM(i ~ a*(t)^b, start = list(a=0.1, b=1))
model3 = nlsLM(i ~ a*exp(c*t), start = list(a=1,c=0.0001))
model4 = nlsLM(i ~ a*(log(abs(t+d1))), start=list(a=0.1 ,d1=1))
# models with intercept
model0i = nlsLM(i ~ a*t+d,start=list(a=1, d=1))
model1i = nlsLM(i ~ a*sqrt(t)+d,start=list(a=1, d=1))
model2i = nlsLM(i ~ a*((t)^b)+d, start = list(a=0.1, b=1, d=1), control=nls.lm.control(maxiter = 150))
model3i = nlsLM(i ~ d+a*exp(c*t), start = list(a=1,c=0.01, d=0.1))
model4i = nlsLM(i ~ a*(log(abs(t+d1)))+d2, start=list(a=10 ,d1=1000, d2=-100))
# the models computer are now inserted in a list to compact the code
models_list = list(model0, model1, model2, model3, model4,
model0i, model1i, model2i, model3i, model4i)
get_RSS = function(x) return(sum(i-predict(x))^2) #check
get_AIC = function(rss, par) return(t.max*log(2*pi) + t.max*log(rss/t.max) + t.max + 2*(par + 1))
get_params = function(x) return(as.vector(summary(x)$coefficients[,1]))
# get parameter estimate from models..
pm = lapply(models_list, get_params)
# replace missing parameters with NA (some models have 1 params others 2, others 3)..
pm = lapply(pm, `length<-`, max(lengths(pm)))
# transform it into matrix to append in the dataframe
pm = do.call(rbind, pm)
# residual sum of squares
rss = sapply(models_list, get_RSS)
# Akaike information criterion
aic_vect = mapply(get_AIC,rss, mod_params)
# model selection growth + preferential attachment
ms_gp = data.frame("RSS"= rss,      # residual square of sum no intercept
"AIC"=aic_vect,  # aic no intercept
"Param1"=pm[,1],          # param 1
"Param2"=pm[,2],          # param 2
"Param3"=pm[,3])          # param
# add model names to df
rownames(ms_gp) = c("linear regr", "plaw 0.5", "plaw", "expo", "log",
"linear regr+i", "plaw 0.5+i", "plaw+i", "expo+i", "log+i")
# show the one that fit better
better_fit = ms_gp[which.min(ms_gp$AIC),]
print(better_fit)
}
apply(test,2,prova)
?mapply
df = do.call(rbind, apply(test,2, prova))
df
prova = function(i){
# models without intercept
model0 = nlsLM(i ~ a*t, start=list(a=1))
model1 = nlsLM(i ~ a*sqrt(t),start=list(a=1))
model2 = nlsLM(i ~ a*(t)^b, start = list(a=0.1, b=1))
model3 = nlsLM(i ~ a*exp(c*t), start = list(a=1,c=0.0001))
model4 = nlsLM(i ~ a*(log(abs(t+d1))), start=list(a=0.1 ,d1=1))
# models with intercept
model0i = nlsLM(i ~ a*t+d,start=list(a=1, d=1))
model1i = nlsLM(i ~ a*sqrt(t)+d,start=list(a=1, d=1))
model2i = nlsLM(i ~ a*((t)^b)+d, start = list(a=0.1, b=1, d=1), control=nls.lm.control(maxiter = 150))
model3i = nlsLM(i ~ d+a*exp(c*t), start = list(a=1,c=0.01, d=0.1))
model4i = nlsLM(i ~ a*(log(abs(t+d1)))+d2, start=list(a=10 ,d1=1000, d2=-100))
# the models computer are now inserted in a list to compact the code
models_list = list(model0, model1, model2, model3, model4,
model0i, model1i, model2i, model3i, model4i)
get_RSS = function(x) return(sum(i-predict(x))^2) #check
get_AIC = function(rss, par) return(t.max*log(2*pi) + t.max*log(rss/t.max) + t.max + 2*(par + 1))
get_params = function(x) return(as.vector(summary(x)$coefficients[,1]))
# get parameter estimate from models..
pm = lapply(models_list, get_params)
# replace missing parameters with NA (some models have 1 params others 2, others 3)..
pm = lapply(pm, `length<-`, max(lengths(pm)))
# transform it into matrix to append in the dataframe
pm = do.call(rbind, pm)
# residual sum of squares
rss = sapply(models_list, get_RSS)
# Akaike information criterion
aic_vect = mapply(get_AIC,rss, mod_params)
# model selection growth + preferential attachment
ms_gp = data.frame("RSS"= rss,      # residual square of sum no intercept
"AIC"=aic_vect,  # aic no intercept
"Param1"=pm[,1],          # param 1
"Param2"=pm[,2],          # param 2
"Param3"=pm[,3])          # param
# add model names to df
rownames(ms_gp) = c("linear regr", "plaw 0.5", "plaw", "expo", "log",
"linear regr+i", "plaw 0.5+i", "plaw+i", "expo+i", "log+i")
# show the one that fit better
better_fit = ms_gp[which.min(ms_gp$AIC),]
}
df = do.call(rbind, apply(test,2, prova))
prova = function(i){
# models without intercept
model0 = nlsLM(i ~ a*t, start=list(a=1))
model1 = nlsLM(i ~ a*sqrt(t),start=list(a=1))
model2 = nlsLM(i ~ a*(t)^b, start = list(a=0.1, b=1))
model3 = nlsLM(i ~ a*exp(c*t), start = list(a=1,c=0.0001))
model4 = nlsLM(i ~ a*(log(abs(t+d1))), start=list(a=0.1 ,d1=1))
# models with intercept
model0i = nlsLM(i ~ a*t+d,start=list(a=1, d=1))
model1i = nlsLM(i ~ a*sqrt(t)+d,start=list(a=1, d=1))
model2i = nlsLM(i ~ a*((t)^b)+d, start = list(a=0.1, b=1, d=1), control=nls.lm.control(maxiter = 150))
model3i = nlsLM(i ~ d+a*exp(c*t), start = list(a=1,c=0.01, d=0.1))
model4i = nlsLM(i ~ a*(log(abs(t+d1)))+d2, start=list(a=10 ,d1=1000, d2=-100))
# the models computer are now inserted in a list to compact the code
models_list = list(model0, model1, model2, model3, model4,
model0i, model1i, model2i, model3i, model4i)
get_RSS = function(x) return(sum(i-predict(x))^2) #check
get_AIC = function(rss, par) return(t.max*log(2*pi) + t.max*log(rss/t.max) + t.max + 2*(par + 1))
get_params = function(x) return(as.vector(summary(x)$coefficients[,1]))
# get parameter estimate from models..
pm = lapply(models_list, get_params)
# replace missing parameters with NA (some models have 1 params others 2, others 3)..
pm = lapply(pm, `length<-`, max(lengths(pm)))
# transform it into matrix to append in the dataframe
pm = do.call(rbind, pm)
# residual sum of squares
rss = sapply(models_list, get_RSS)
# Akaike information criterion
aic_vect = mapply(get_AIC,rss, mod_params)
model_name = c("linear regr", "plaw 0.5", "plaw", "expo", "log",
"linear regr+i", "plaw 0.5+i", "plaw+i", "expo+i", "log+i")
# model selection growth + preferential attachment
ms_gp = data.frame("Model" = model_name,
"RSS"= rss,      # residual square of sum no intercept
"AIC"=aic_vect,  # aic no intercept
"Param1"=pm[,1],          # param 1
"Param2"=pm[,2],          # param 2
"Param3"=pm[,3])          # param
# add model names to df
# show the one that fit better
better_fit = ms_gp[which.min(ms_gp$AIC),]
}
df = do.call(rbind, apply(test,2, prova))
df
